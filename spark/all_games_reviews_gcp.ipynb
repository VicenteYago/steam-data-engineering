{"cells":[{"cell_type":"markdown","metadata":{},"source":["## All reviews from all games"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'/opt/conda/miniconda3/bin/python'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import sys\n","import pyspark\n","import os\n","from pyspark.sql import SparkSession\n","from pyspark.conf import SparkConf\n","from pyspark import SparkContext\n","from pyspark.sql.functions import input_file_name\n","from pyspark.sql import functions as F\n","from pyspark.sql import Row\n","from pyspark.sql.functions import row_number,lit\n","from pyspark.sql.window import Window\n","import re\n","from pyspark.sql.types import StringType\n","from google.api_core import page_iterator\n","from google.cloud import storage\n","\n","sys.executable"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#CREDENTIALS = '/home/vyago/.google/credentials/google_credentials.json'\n","#GCS_JAR = \"./lib/gcs-connector-hadoop3-latest.jar\"\n","\n","BQ_JAR = \"gs://spark-lib/bigquery/spark-3.1-bigquery-0.27.0-preview.jar\"\n","BQ_PROJECT_ID = \"steam-data-engineering-gcp\"\n","BQ_DATASET = 'steam_raw'\n","BQ_TABLE = 'reviews'\n","\n","TEMP_BUCKET = 'steam-datalake-dataset'\n","BUCKET = \"steam-datalake-reviews\"\n","BUCKET_SUBDIR = \"proc\"\n","\n","conf = SparkConf() \\\n","    .setAppName('steam-gcp-dataproc') \\\n","    .set(\"spark.jars\", f\"{BQ_JAR}\") \\\n","    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n","\n","#   .setMaster('local[*]') \\\n","#   .set(\"spark.jars\", f\"{GCS_JAR}, {BQ_JAR}\") \\\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/09/26 17:12:37 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n","22/09/26 17:12:37 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n","22/09/26 17:12:37 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n","22/09/26 17:12:37 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"]}],"source":["sc = SparkContext(conf=conf)\n","\n","#hadoop_conf = sc._jsc.hadoopConfiguration()\n","#hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n","#hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n","#hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", CREDENTIALS)\n","#hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder \\\n","    .config(conf=sc.getConf()) \\\n","    .getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["Connect to GCS"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# https://stackoverflow.com/questions/49538327/pyspark-string-pattern-from-columns-values-and-regexp-expression\n","\n","def flatten_df(nested_df):\n","    flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] != 'struct']\n","    nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'struct']\n","\n","    flat_df = nested_df.select(flat_cols +\n","                               [F.col(nc+'.'+c).alias(nc+'_'+c)\n","                                for nc in nested_cols\n","                                for c in nested_df.select(nc+'.*').columns])\n","    return flat_df\n","\n","\n","def proc_json(raw_df, field)  :\n","    rows = raw_df[field]\n","    return(rows)\n","\n","def get_previous_word(text):\n","    matches = re.search('.*/(\\d+)-.*', text)\n","    return matches.group(1)\n","\n","extract_game_id = F.udf(\n","    lambda text: get_previous_word(text),\n","    StringType()\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["Read data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- cursor: string (nullable = true)\n"," |-- query_summary: struct (nullable = true)\n"," |    |-- num_reviews: long (nullable = true)\n"," |    |-- review_score: long (nullable = true)\n"," |    |-- review_score_desc: string (nullable = true)\n"," |    |-- total_negative: long (nullable = true)\n"," |    |-- total_positive: long (nullable = true)\n"," |    |-- total_reviews: long (nullable = true)\n"," |-- reviews: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- author: struct (nullable = true)\n"," |    |    |    |-- last_played: long (nullable = true)\n"," |    |    |    |-- num_games_owned: long (nullable = true)\n"," |    |    |    |-- num_reviews: long (nullable = true)\n"," |    |    |    |-- playtime_at_review: long (nullable = true)\n"," |    |    |    |-- playtime_forever: long (nullable = true)\n"," |    |    |    |-- playtime_last_two_weeks: long (nullable = true)\n"," |    |    |    |-- steamid: string (nullable = true)\n"," |    |    |-- comment_count: long (nullable = true)\n"," |    |    |-- language: string (nullable = true)\n"," |    |    |-- received_for_free: boolean (nullable = true)\n"," |    |    |-- recommendationid: string (nullable = true)\n"," |    |    |-- review: string (nullable = true)\n"," |    |    |-- steam_purchase: boolean (nullable = true)\n"," |    |    |-- timestamp_created: long (nullable = true)\n"," |    |    |-- timestamp_updated: long (nullable = true)\n"," |    |    |-- voted_up: boolean (nullable = true)\n"," |    |    |-- votes_funny: long (nullable = true)\n"," |    |    |-- votes_up: long (nullable = true)\n"," |    |    |-- weighted_vote_score: string (nullable = true)\n"," |    |    |-- written_during_early_access: boolean (nullable = true)\n"," |-- success: long (nullable = true)\n"," |-- filename: string (nullable = false)\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["all_games = spark.read.json(f\"gs://{BUCKET}/{BUCKET_SUBDIR}/*\", multiLine=True) \\\n","                      .withColumn(\"filename\", input_file_name())\n","all_games.printSchema()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 3:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+-------+--------------------+\n","|              cursor|       query_summary|             reviews|success|            filename|\n","+--------------------+--------------------+--------------------+-------+--------------------+\n","|AoJ4qo/0rPoCfp6b6QI=|{100, null, null,...|[{{1656197665, 74...|      1|gs://steam-datala...|\n","|AoJw5pWI/v0CetHvlgM=|{100, null, null,...|[{{1643432700, 14...|      1|gs://steam-datala...|\n","|AoJ4qaHj9vICfueVkAI=|{100, null, null,...|[{{1596365869, 69...|      1|gs://steam-datala...|\n","|AoJwrseHlf0Ce/HBiAM=|{100, null, null,...|[{{1640537142, 27...|      1|gs://steam-datala...|\n","|AoJw9Y+FhIEDe/P3ugM=|{100, null, null,...|[{{1656626369, 36...|      1|gs://steam-datala...|\n","|AoJ47pP/yPACerap9QE=|{100, null, null,...|[{{1660175584, 10...|      1|gs://steam-datala...|\n","|AoJwwqSC+MgCdZSsLw==|{100, null, null,...|[{{1590322827, 27...|      1|gs://steam-datala...|\n","|AoJ49q3f3/ECfNaBhAI=|{100, null, null,...|[{{1646058950, 13...|      1|gs://steam-datala...|\n","|AoJw86KGwuoCcNHHwAE=|{100, null, null,...|[{{1650057700, 17...|      1|gs://steam-datala...|\n","|    AoJ4z7WCh7MCeLhF|{100, null, null,...|[{{1385003206, 32...|      1|gs://steam-datala...|\n","|AoJw8dOOid0Cfbv0fg==|{100, null, null,...|[{{1658370659, 66...|      1|gs://steam-datala...|\n","|AoJ404fc5esCeLrIzQE=|{100, null, null,...|[{{1561623030, 28...|      1|gs://steam-datala...|\n","|AoJ4ofHLuNICeMiCTw==|{100, null, null,...|[{{1461632695, 45...|      1|gs://steam-datala...|\n","|AoJw+uXFjOMCeL2ynwE=|{100, null, null,...|[{{1530380861, 31...|      1|gs://steam-datala...|\n","|AoJwirPN0+sCf7DRxwE=|{100, null, null,...|[{{1562413908, 52...|      1|gs://steam-datala...|\n","|AoJ4z8eN78YCcq++KQ==|{100, null, null,...|[{{1432432089, 35...|      1|gs://steam-datala...|\n","|AoJ4uq3o4NACfPLfRw==|{100, null, null,...|[{{1447654605, 36...|      1|gs://steam-datala...|\n","|AoJ4gsmG2tsCerDqdw==|{100, null, null,...|[{{1590094507, 21...|      1|gs://steam-datala...|\n","|AoJ4weLVmNQCc5f3VQ==|{100, null, null,...|[{{1537736669, 53...|      1|gs://steam-datala...|\n","|AoJ4zpfV/uYCeqS9rgE=|{100, null, null,...|[{{1566471273, 76...|      1|gs://steam-datala...|\n","+--------------------+--------------------+--------------------+-------+--------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["all_games.show() # compute intesive WARNING !"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["rdd = all_games.rdd\n","rdd = rdd.repartition(5)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 4:>                                                          (0 + 2) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["Number of files processed: 97\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["print(f\"Number of files processed: {rdd.count()}\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Nº partitons:  5\n"]}],"source":["print(\"Nº partitons: \", rdd.getNumPartitions())"]},{"cell_type":"markdown","metadata":{},"source":["### Reviews "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- author: struct (nullable = true)\n"," |    |-- last_played: long (nullable = true)\n"," |    |-- num_games_owned: long (nullable = true)\n"," |    |-- num_reviews: long (nullable = true)\n"," |    |-- playtime_at_review: long (nullable = true)\n"," |    |-- playtime_forever: long (nullable = true)\n"," |    |-- playtime_last_two_weeks: long (nullable = true)\n"," |    |-- steamid: string (nullable = true)\n"," |-- comment_count: long (nullable = true)\n"," |-- language: string (nullable = true)\n"," |-- received_for_free: boolean (nullable = true)\n"," |-- recommendationid: string (nullable = true)\n"," |-- review: string (nullable = true)\n"," |-- steam_purchase: boolean (nullable = true)\n"," |-- timestamp_created: long (nullable = true)\n"," |-- timestamp_updated: long (nullable = true)\n"," |-- voted_up: boolean (nullable = true)\n"," |-- votes_funny: long (nullable = true)\n"," |-- votes_up: long (nullable = true)\n"," |-- weighted_vote_score: string (nullable = true)\n"," |-- written_during_early_access: boolean (nullable = true)\n","\n"]},{"name":"stderr","output_type":"stream","text":["22/09/26 17:14:27 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 7.0 (TID 11) (cluster-11ee-w-1.europe-west1-b.c.steam-data-engineering-gcp.internal executor 2): org.apache.spark.util.TaskCompletionListenerException: refCnt: 0, decrement: 1\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:145)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:124)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","\n"]}],"source":["df_reviews = rdd.flatMap(lambda item : proc_json(item, field = \"reviews\")) \\\n","                .toDF()\n","df_reviews.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Game ID "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- gameid: string (nullable = true)\n","\n"]}],"source":["df_gameid = rdd.map(  lambda item : [ proc_json(item, field = \"reviews\"),\n","                                      proc_json(item, field = \"filename\")] ) \\\n","               .flatMap(lambda item:  [item[1] for i in item[0] ]) \\\n","               .map(lambda item : Row(gameid  = item, )).toDF()\n","\n","df_gameid = df_gameid.withColumn('gameid', extract_game_id('gameid'))\n","df_gameid.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Join dataframes"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["w = Window().orderBy(lit('A'))\n","df_reviews = df_reviews.withColumn(\"row_num\", row_number().over(w))\n","df_gameid = df_gameid.withColumn(\"row_num\", row_number().over(w))\n","\n","df_reviews = df_reviews.join(df_gameid, on = [\"row_num\"], how = \"inner\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- row_num: integer (nullable = true)\n"," |-- author: struct (nullable = true)\n"," |    |-- last_played: long (nullable = true)\n"," |    |-- num_games_owned: long (nullable = true)\n"," |    |-- num_reviews: long (nullable = true)\n"," |    |-- playtime_at_review: long (nullable = true)\n"," |    |-- playtime_forever: long (nullable = true)\n"," |    |-- playtime_last_two_weeks: long (nullable = true)\n"," |    |-- steamid: string (nullable = true)\n"," |-- comment_count: long (nullable = true)\n"," |-- language: string (nullable = true)\n"," |-- received_for_free: boolean (nullable = true)\n"," |-- recommendationid: string (nullable = true)\n"," |-- review: string (nullable = true)\n"," |-- steam_purchase: boolean (nullable = true)\n"," |-- timestamp_created: long (nullable = true)\n"," |-- timestamp_updated: long (nullable = true)\n"," |-- voted_up: boolean (nullable = true)\n"," |-- votes_funny: long (nullable = true)\n"," |-- votes_up: long (nullable = true)\n"," |-- weighted_vote_score: string (nullable = true)\n"," |-- written_during_early_access: boolean (nullable = true)\n"," |-- gameid: string (nullable = true)\n","\n"]}],"source":["df_reviews.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_reviews.count() # compute intesive WARNING !"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_reviews.take(1) # compute intesive WARNING !"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- row_num: integer (nullable = true)\n"," |-- comment_count: long (nullable = true)\n"," |-- language: string (nullable = true)\n"," |-- received_for_free: boolean (nullable = true)\n"," |-- recommendationid: string (nullable = true)\n"," |-- review: string (nullable = true)\n"," |-- steam_purchase: boolean (nullable = true)\n"," |-- timestamp_created: long (nullable = true)\n"," |-- timestamp_updated: long (nullable = true)\n"," |-- voted_up: boolean (nullable = true)\n"," |-- votes_funny: long (nullable = true)\n"," |-- votes_up: long (nullable = true)\n"," |-- weighted_vote_score: string (nullable = true)\n"," |-- written_during_early_access: boolean (nullable = true)\n"," |-- gameid: string (nullable = true)\n"," |-- author_last_played: long (nullable = true)\n"," |-- author_num_games_owned: long (nullable = true)\n"," |-- author_num_reviews: long (nullable = true)\n"," |-- author_playtime_at_review: long (nullable = true)\n"," |-- author_playtime_forever: long (nullable = true)\n"," |-- author_playtime_last_two_weeks: long (nullable = true)\n"," |-- author_steamid: string (nullable = true)\n","\n"]}],"source":["df_reviews_flat = flatten_df(df_reviews) \n","df_reviews_flat.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Write into BigQuery"]},{"cell_type":"markdown","metadata":{},"source":["- https://github.com/GoogleCloudDataproc/spark-bigquery-connector"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/09/26 17:16:07 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:07 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:08 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:08 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:08 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:09 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:09 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","22/09/26 17:16:09 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","                                                                                \r"]}],"source":["# Saving the data to BigQuery\n","df_reviews_flat.write \\\n","  .format('bigquery') \\\n","  .option('table', f'{BQ_PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}') \\\n","  .mode(\"append\") \\\n","  .option(\"temporaryGcsBucket\",TEMP_BUCKET) \\\n","  .save()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"b60d76cc204c3a2caf44ab1915661f58ff09a8919b71fd1dfd9e0ece822b469f"}}},"nbformat":4,"nbformat_minor":2}